<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="x-ua-compatible" content="ie=edge" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover" />

  <style>
    :root {
      --accent-overlay-color: #fff;
      --body-bg: #fff;
      --body-color: #000;
      --heading-color: #000;
      --table-bg-even: #f3f3f3;
      --table-border-bottom: #dddddd;
      --code-bg: #f1f1f1;
      --code-color: #6e6b5e;
    }

    [data-theme="dark"] {
      --accent-overlay-color: #dee2e6;
      --body-bg: #212529;
      --body-color: #abb2bf;
      --heading-color: #dee2e6;
      --table-bg-even: #2d3237;
      --table-border-bottom: #697077;
      --code-bg: #2d3237;
      --code-color: #abb2bf;
    }

    [data-theme="dark"] img {
      opacity: .75;
      transition: opacity .5s ease-in-out;
    }

    [data-theme="dark"] img:hover {
      opacity: 1;
    }

    [data-theme="dark"] table thead tr {
      background-color: var(--table-bg-even);
      color: var(--heading-color);
    }

    [data-theme="dark"] table tbody tr:last-of-type {
      border-bottom: 2px solid var(--table-border-bottom);
    }

    .theme-toggle {
      cursor: pointer;
      padding: 0 10px;
      background: none;
      border: none;
      color: var(--body-color);
      font-size: 1.2rem;
    }

    @media (max-width: 600px) {
      header {
        gap: 0;
      }

      header nav {
        display: flex;
        flex-wrap: nowrap;
        white-space: nowrap;
        overflow-x: auto;
        overflow-y: hidden;
        -webkit-overflow-scrolling: touch;
        scrollbar-width: none;
      }

      header nav::-webkit-scrollbar {
        display: none;
      }

      header nav>a {
        flex: 0 0 auto;
      }

      header nav>a.nav-projects,
      header nav>a.nav-resume {
        display: none;
      }

      header nav>a:not(:last-child) {
        margin-right: 0.3rem;
      }

      .theme-toggle {
        flex: 0 0 auto;
        padding: 0 2px;
      }
    }

    .active-nav {
      color: var(--accent-color);
      font-weight: bold;
    }
  </style>

  <script>
    (function () {
      const localTheme = localStorage.getItem("theme");
      const systemTheme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light";
      const theme = localTheme || systemTheme;
      document.documentElement.setAttribute("data-theme", theme);

      // Inject CSS variables from Zola config to prevent formatter issues
      const root = document.documentElement;
      root.style.setProperty('--accent-color', '#05a081');
      root.style.setProperty('--accent-color-light', '#82d0c0');
    })();
  </script>

  <meta name="theme-color" content="#05a081" />

  
  <link rel="icon" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.5bc282474aa9c014.jpg" />
  <link rel="apple-touch-icon" sizes="48x48" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.5bc282474aa9c014.jpg" />
  <link rel="apple-touch-icon" sizes="72x72" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.fe16e0bb11047769.jpg" />
  <link rel="apple-touch-icon" sizes="96x96" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.605594d8be6a111f.jpg" />
  <link rel="apple-touch-icon" sizes="144x144" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.3d1b2eeabf8eca47.jpg" />
  <link rel="apple-touch-icon" sizes="192x192" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.b6439cbc27d70267.jpg" />
  <link rel="apple-touch-icon" sizes="256x256" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.e69fb5473e9ea744.jpg" />
  <link rel="apple-touch-icon" sizes="384x384" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.d03b11f47410640c.jpg" />
  <link rel="apple-touch-icon" sizes="512x512" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.d847062c67ed9f5e.jpg" />
  
  

  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JD979V1BWS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag("js", new Date());
    gtag("config", "G-JD979V1BWS");
  </script>
  

  <meta property="og:type" content="website">

  <meta name="twitter:card" content="summary">

  

  

  
  
  <meta name="description" content="" />
  <meta name="twitter:description" content="">
  
  

  
  <meta name="twitter:title" content="GenAI Models">
  

  
  <link rel="prerender" href="&#x2F;resume&#x2F;" />
  
  <link rel="prerender" href="&#x2F;blog&#x2F;" />
  
  <link rel="prerender" href="&#x2F;projects&#x2F;" />
  
  <link rel="prerender" href="&#x2F;books&#x2F;" />
  
  <link rel="prerender" href="&#x2F;interviews&#x2F;" />
  
  <link rel="prerender" href="&#x2F;generative-ai&#x2F;" />
  

  <link rel="prefetch" href="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.db45dd197188a7fb.jpg" />

  <title>
    



Gal's 
     
    
        Generative AI
    
 Book - GenAI Models


  </title>

  
  


<link rel="stylesheet" href="https://gel.github.io/main.css">
<link rel="stylesheet" href="https://gel.github.io/book.css">



  





  
  <script src="https://gel.github.io/animations.js" defer></script>
  <script type="module">
    import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs";

    function getTheme() {
      return document.documentElement.getAttribute("data-theme") === "dark" ? "dark" : "default";
    }

    mermaid.initialize({
      startOnLoad: false,
      theme: getTheme(),
      securityLevel: "loose",
      fontFamily: "inherit"
    });

    async function initMermaid() {
      const codeBlocks = document.querySelectorAll("pre code.language-mermaid, pre code[data-lang='mermaid']");
      for (const block of codeBlocks) {
        const pre = block.parentElement;
        const code = block.textContent;
        const div = document.createElement("div");
        div.className = "mermaid";
        div.setAttribute("data-original-code", code);
        div.textContent = code;
        pre.replaceWith(div);
      }
      await renderMermaid();
    }

    async function renderMermaid() {
      const mermaidDivs = document.querySelectorAll("div.mermaid");
      if (mermaidDivs.length === 0) return;

      const currentTheme = getTheme();
      const themeVars = currentTheme === 'dark' ? {
        'primaryColor': '#2d3237',
        'primaryTextColor': '#abb2bf',
        'primaryBorderColor': '#697077',
        'lineColor': '#abb2bf',
        'secondaryColor': '#212529',
        'tertiaryColor': '#2d3237',
        'mainBkg': '#2d3237',
        'nodeBorder': '#697077'
      } : {};

      mermaid.initialize({
        startOnLoad: false,
        theme: currentTheme === 'dark' ? 'base' : 'default',
        themeVariables: themeVars
      });

      mermaidDivs.forEach(div => {
        const originalCode = div.getAttribute("data-original-code");
        if (originalCode) {
          div.textContent = originalCode;
          div.removeAttribute("data-processed");
        }
      });

      await mermaid.run({ nodes: mermaidDivs });
    }

    document.addEventListener("DOMContentLoaded", initMermaid);

    window.addEventListener("themeChanged", async () => {
      await renderMermaid();
    });
  </script>
</head>

<body class="book-body">
  
  <header>
    <a class="profile-icon" href="/">
      <img src="https:&#x2F;&#x2F;gel.github.io&#x2F;processed_images&#x2F;iconweb.db45dd197188a7fb.jpg" alt="profile picture">
    </a>
    <nav>
      
      <a href="&#x2F;resume&#x2F;"
        class="nav-resume
        "
      >Resume</a>
      
      <a href="&#x2F;blog&#x2F;"
        class="nav-blog
        "
      >Blog</a>
      
      <a href="&#x2F;projects&#x2F;"
        class="nav-projects
        "
      >Projects</a>
      
      <a href="&#x2F;books&#x2F;"
        class="nav-books
        "
      >Books</a>
      
      <a href="&#x2F;interviews&#x2F;"
        class="nav-interviews
        "
      >Interviews</a>
      
      <a href="&#x2F;generative-ai&#x2F;"
        class="nav-genai
        active-nav"
      >GenAI</a>
      
      
      <button class="theme-toggle" aria-label="Toggle Dark Mode" onclick="toggleTheme()">
        <span class="theme-icon-light">‚òÄÔ∏è</span>
        <span class="theme-icon-dark" style="display:none">üåô</span>
      </button>
      
    </nav>
  </header>
  
  <main>
    
<!-- Sidebar defaults to class 'menu'. CSS max-width 600px breakpoint handles closing it automatically -->
<div class="menu">
  
  
  <nav role="navigation">
    <ul>
      
      
      
      
      
      
      
      
      
      
      
      <li >
        <a href="https://gel.github.io/generative-ai/1-intro/">
          <strong>1.</strong>
          Generative AI Foundations
        </a>
        
        <ul>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;1-intro&#x2F;1-genai-environment&#x2F;">
              <strong>1.1.</strong>
              GenAI Agents Environment
            </a>
          </li>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;1-intro&#x2F;2-genai-agents-tricks&#x2F;">
              <strong>1.2.</strong>
              GenAI Agents Tricks
            </a>
          </li>
          
        </ul>
        
      </li>
      
      
      
      
      
      
      <li >
        <a href="https://gel.github.io/generative-ai/2-genai-research/">
          <strong>2.</strong>
          GenAI Research
        </a>
        
        <ul>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;2-genai-research&#x2F;1-genai-agents&#x2F;">
              <strong>2.1.</strong>
              Agents
            </a>
          </li>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;2-genai-research&#x2F;2-genai-pretraining-finetuning&#x2F;">
              <strong>2.2.</strong>
              GenAI Training
            </a>
          </li>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;2-genai-research&#x2F;3-genai-optimization&#x2F;">
              <strong>2.3.</strong>
              GenAI Optimizations
            </a>
          </li>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;2-genai-research&#x2F;4-genai-prompting&#x2F;">
              <strong>2.4.</strong>
              GenAI Prompting
            </a>
          </li>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;2-genai-research&#x2F;5-genai-benchmarks&#x2F;">
              <strong>2.5.</strong>
              GenAI Evaluations
            </a>
          </li>
          
          <li class="active" >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;2-genai-research&#x2F;6-genai-models&#x2F;">
              <strong>2.6.</strong>
              GenAI Models
            </a>
          </li>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;2-genai-research&#x2F;7-genai-security&#x2F;">
              <strong>2.7.</strong>
              GenAI Security
            </a>
          </li>
          
        </ul>
        
      </li>
      
      
      
      
      
      
      <li >
        <a href="https://gel.github.io/generative-ai/3-llm-implementation/">
          <strong>3.</strong>
          LLM Implementation
        </a>
        
        <ul>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;3-llm-implementation&#x2F;1-datasets&#x2F;">
              <strong>3.1.</strong>
              Datasets
            </a>
          </li>
          
          <li >
            <a href="https:&#x2F;&#x2F;gel.github.io&#x2F;generative-ai&#x2F;3-llm-implementation&#x2F;2-llms&#x2F;">
              <strong>3.2.</strong>
              LLMs
            </a>
          </li>
          
        </ul>
        
      </li>
      
      
      
    </ul>
  </nav>
  
  
</div>

<!-- Page defaults to class 'page'. CSS max-width 600px breakpoint handles making it full-width automatically -->
<div class="page">

  <div class="page__content">
    
    <div class="search-container">
      <input id="search" type="search" placeholder="Search..">
      <div class="search-results">
        <div class="search-results__header"></div>
        <ul class="search-results__items"></ul>
      </div>
    </div>
    
    <button class="sidebar-toggle-inline" id="sidebar-toggle-inline" aria-label="Toggle Chapters">
      <span class="toggle-icon">‚ò∞</span> Chapters
    </button>
    <div class="book-content">
      
    <h1>GenAI Models</h1>
    <h3 id="survey-a-survey-of-reshaping-the-genai-research-landscape">[Survey] A Survey of Reshaping the GenAI Research Landscape<a class="zola-anchor" href="#survey-a-survey-of-reshaping-the-genai-research-landscape" aria-label="Anchor link for: survey-a-survey-of-reshaping-the-genai-research-landscape">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2312.10868">https://arxiv.org/abs/2312.10868</a> <em>18 Dec 2023  <strong>IEEE</strong></em></p>
<p>This survey explores Generative AI (AI), focusing on Mixture of Experts (MoE), multimodal learning, and the path towards Artificial General Intelligence (AGI).</p>
<h2 id="text-multimodal-llms">Text &amp; Multimodal LLMs<a class="zola-anchor" href="#text-multimodal-llms" aria-label="Anchor link for: text-multimodal-llms">üîó</a></h2>
<h3 id="mixtral-mixtral-of-experts">[Mixtral] Mixtral of Experts<a class="zola-anchor" href="#mixtral-mixtral-of-experts" aria-label="Anchor link for: mixtral-mixtral-of-experts">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2401.04088">https://arxiv.org/abs/2401.04088</a> <em>8 Jan 2024 <strong>Mixtral.ai</strong></em></p>
<p>We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts).</p>
<p><img src="/generative-ai/2-genai-research/llm_7_mistral1.png" alt="Mistral Experts" /></p>
<ul>
<li>G denotes n dimensionality of the gating network (router), E is the expert network.</li>
</ul>
<p>Consecutive tokens are often assigned to the same experts. In fact, we observe some degree of positional locality in The Pile datasets. Table 5 shows the proportion of consecutive tokens that get the same expert assignments per domain and layer. Figures are not showing it clearly.</p>
<p><img src="/generative-ai/2-genai-research/llm_7_mistral2.png" alt="Mistral Decoding" /></p>
<h3 id="gemini-a-family-of-highly-capable-multimodal-models">[Gemini] A Family of Highly Capable Multimodal Models<a class="zola-anchor" href="#gemini-a-family-of-highly-capable-multimodal-models" aria-label="Anchor link for: gemini-a-family-of-highly-capable-multimodal-models">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2312.11805">https://arxiv.org/abs/2312.11805</a> <em>19 Dec 2023 <strong>Google</strong></em></p>
<p>The reasoning capabilities of large language models show promise toward building generalist agents that can tackle more complex multi-step problems.</p>
<p><img src="/generative-ai/2-genai-research/llm_7_gemini1.png" alt="Gemini Sample" /></p>
<p><img src="/generative-ai/2-genai-research/llm_7_gemini2.png" alt="Gemini Architecture" /></p>
<h3 id="modernbert-modern-bidirectional-encoder">[ModernBERT] Modern Bidirectional Encoder<a class="zola-anchor" href="#modernbert-modern-bidirectional-encoder" aria-label="Anchor link for: modernbert-modern-bidirectional-encoder">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2412.13663">https://arxiv.org/abs/2412.13663</a> <em>18 Dec 2024</em></p>
<p>The paper introduces ModernBERT, a new family of encoder-only transformer models that brings modern optimizations to BERT-style architectures.</p>
<p>Key Features:</p>
<ol>
<li>
<p>Architectural Improvements:</p>
<ul>
<li>Uses GeGLU activation</li>
<li>RoPE positional embeddings</li>
<li>Alternating local-global attention</li>
<li>Native 8192 sequence length</li>
<li>Optimized for efficient inference on common GPUs</li>
<li>Full model unpadding for better efficiency</li>
</ul>
</li>
<li>
<p>Training:</p>
<ul>
<li>Trained on 2 trillion tokens</li>
<li>Includes code data in training mixture</li>
<li>Uses modern BPE tokenizer with 50,368 vocabulary size</li>
</ul>
</li>
<li>
<p>Unique Advantages:</p>
<ul>
<li>Successfully combines modern LLM architecture improvements with encoder-only models</li>
<li>Achieves better performance while maintaining high efficiency</li>
<li>Represents first major Pareto improvement over older encoders like BERT</li>
<li>Code-Aware Design: Uses a code-aware tokenizer that can properly handle programming syntax</li>
<li>The code training makes ModernBERT uniquely suited for code-related tasks while maintaining strong performance on traditional NLP tasks</li>
</ul>
</li>
</ol>
<p>Limitations:</p>
<ul>
<li>MLM-only objective (Masked Language Modeling)</li>
<li>Not trained with RTD (Replaced Token Detection) which might hurt classification results</li>
</ul>
<h3 id="gliner-generalist-model-for-ner-using-bidirectional-transformer">[GLiNER] Generalist Model for NER using Bidirectional Transformer<a class="zola-anchor" href="#gliner-generalist-model-for-ner-using-bidirectional-transformer" aria-label="Anchor link for: gliner-generalist-model-for-ner-using-bidirectional-transformer">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2311.08526">https://arxiv.org/abs/2311.08526</a> <em>14 Nov 2023</em></p>
<pre data-lang="mermaid" class="language-mermaid "><code class="language-mermaid" data-lang="mermaid">flowchart LR
    Text[Input Text] --&gt; Enc[Bidirectional\nEncoder]
    Types[&quot;Entity Types\n(any types)&quot;] --&gt; Enc
    Enc --&gt; Spans[Span\nRepresentations]
    Enc --&gt; Entities[Entity\nRepresentations]
    Spans --&gt; Match{Match in\nLatent Space}
    Entities --&gt; Match
    Match --&gt; NER[&quot;Named Entities\n(Parallel Extraction)&quot;]

    style NER fill:#c8e6c9,color:#000
</code></pre>
<p>Key Points:</p>
<p>Problem &amp; Solution:</p>
<ul>
<li>Traditional NER models are limited to predefined entity types</li>
<li>GLiNER introduces a compact model that can identify any type of entity</li>
<li>Uses bidirectional transformer encoder for parallel entity extraction</li>
</ul>
<p>Architecture:</p>
<ul>
<li>Uses bidirectional transformer (like BERT/DeBERTa) as backbone</li>
<li>Components:
<ol>
<li>Pre-trained textual encoder</li>
<li>Span representation module</li>
<li>Entity representation module</li>
</ol>
</li>
<li>Treats NER as matching entity types with text spans in latent space</li>
</ul>
<p>Performance:</p>
<ul>
<li>Parallel entity extraction vs sequential generation in LLMs</li>
<li>Compact design (50M-300M parameters) vs billions in LLMs</li>
<li>Effective negative entity sampling during training</li>
<li>Entity type dropping as regularization technique</li>
</ul>
<p>Limitations:</p>
<ul>
<li>Lower performance on informal text (e.g., tweets)</li>
<li>Reduced effectiveness on non-Latin scripts</li>
<li>Room for improvement in low-resource languages</li>
</ul>
<h2 id="vision-diffusion-models">Vision &amp; Diffusion Models<a class="zola-anchor" href="#vision-diffusion-models" aria-label="Anchor link for: vision-diffusion-models">üîó</a></h2>
<h3 id="training-diffusion-models-with-rl">Training Diffusion Models with RL<a class="zola-anchor" href="#training-diffusion-models-with-rl" aria-label="Anchor link for: training-diffusion-models-with-rl">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2305.13301">https://arxiv.org/abs/2305.13301</a> <em>22 May 2023</em></p>
<ol>
<li>Normalization over contrastive prompts.</li>
<li>Prompt synthesis via LLM.</li>
<li>Incorporating textual inconsistency into the score (calculate distance in embedding space) - avoid synthetically close, semantically different.</li>
</ol>
<h3 id="dpok-rl-for-fine-tuning-text-to-image-diffusion-models">[DPOK] RL for Fine-tuning Text-to-Image Diffusion Models<a class="zola-anchor" href="#dpok-rl-for-fine-tuning-text-to-image-diffusion-models" aria-label="Anchor link for: dpok-rl-for-fine-tuning-text-to-image-diffusion-models">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2305.16381">https://arxiv.org/abs/2305.16381</a> <em>25 May 2023</em></p>
<p>We focus on diffusion models, defining the fine-tuning task as an RL problem, and updating the pre-trained text-to-image diffusion models using policy gradients to maximize the feedback-trained reward. Our approach, coined DPOK, integrates policy optimization with KL regularization.</p>
<p>Generation of more data includes generating n-1 negative samples and leveraging contrastive loss and generating more images to increase diversity.</p>
<p>In fine-tuning the loss function will be the expectancy of the sum of all the binary-human-classified dataset and also loss from the pre-training based data (weighted with B) to maintain accuracy of the model (avoid catastrophic forgetting). For the reward loss the idea is for the reward to be log-likelihood but it‚Äôs not easy, Therefore we minimize reward-weighted MSE loss instead.</p>
<p>Setup: Pretrained Stable Diffusion 1.5, fine-tuning using static CLIP language encoder, Reward model is MLP using ViT-L/14 CLIP for image/text embeddings, Dataset 2700 prompts, 27k images, 16k unlabeled and 625k for pretraining.</p>
<p>SFT: model is updated on a fixed dataset generated by the pre-trained model.</p>
<p>RL: model is updated using new samples from the previously trained model during online RL fine-tuning.</p>
<p>Based on the results, adding KL regularization helps in improving both image fidelity and accuracy (mostly image fidelty).</p>
<h3 id="point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts">[Point-E] A System for Generating 3D Point Clouds from Complex Prompts<a class="zola-anchor" href="#point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts" aria-label="Anchor link for: point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2212.08751">https://arxiv.org/abs/2212.08751</a> <em>16 Dec 2022 <strong>OpenAI</strong></em></p>
<p>In this paper, we explore an alternative method for 3D object generation which produces 3D models in only 1-2 minutes on a single GPU. Our method first generates a single synthetic view using a text-to-image diffusion model, and then produces a 3D point cloud using a second diffusion model which conditions on the generated image.</p>
<p>Using glade dataset for 2D (fine-tuned on 3D rendering).</p>
<h3 id="clip-connecting-text-and-images">[CLIP] Connecting text and images<a class="zola-anchor" href="#clip-connecting-text-and-images" aria-label="Anchor link for: clip-connecting-text-and-images">üîó</a></h3>
<p>Arxiv: <a href="https://arxiv.org/abs/2103.00020">https://arxiv.org/abs/2103.00020</a> <em>26 Feb 2021 <strong>OpenAI</strong></em></p>
<p>CLIP pre-trains an image encoder and a text encoder to predict which images were paired with which texts in our dataset. We then use this behavior to turn CLIP into a zero-shot classifier. We convert all of a dataset‚Äôs classes into captions such as ‚Äúa photo of a dog‚Äù and predict the class of the caption CLIP estimates best pairs with a given image.</p>


    </div>
  </div>

  <nav class="book-pagination">
    <div class="prev-link">
      
    
        
        
        <a class="previous" href="https://gel.github.io/generative-ai/2-genai-research/">&larr; Previous</a>
    

    </div>

    <div class="next-link">
      
    
        <a class="next" href="https://gel.github.io/generative-ai/2-genai-research/7-genai-security/">Next &rarr;</a>
    

    </div>
  </nav>
</div>






<script type="text/javascript" src="https://gel.github.io/elasticlunr.min.js"></script>
<script type="text/javascript" src="https://gel.github.io/search_index.en.js"></script>

<script type="text/javascript" src="https://gel.github.io/book.js"></script>
<script async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  </main>
  <footer class="footer-page">
    
    
    
  </footer>
  <script>
    function toggleTheme() {
      const currentTheme = document.documentElement.getAttribute("data-theme");
      const newTheme = currentTheme === "dark" ? "light" : "dark";

      document.documentElement.setAttribute("data-theme", newTheme);
      localStorage.setItem("theme", newTheme);
      updateIcons(newTheme);

      // Notify other scripts about the theme change
      window.dispatchEvent(new CustomEvent("themeChanged", { detail: { theme: newTheme } }));
    }

    function updateIcons(theme) {
      const lightIcons = document.querySelectorAll(".theme-icon-light");
      const darkIcons = document.querySelectorAll(".theme-icon-dark");

      if (theme === "dark") {
        lightIcons.forEach(icon => icon.style.display = "none");
        darkIcons.forEach(icon => icon.style.display = "inline");
      } else {
        lightIcons.forEach(icon => icon.style.display = "inline");
        darkIcons.forEach(icon => icon.style.display = "none");
      }
    }

    // Initial icon setup
    document.addEventListener("DOMContentLoaded", () => {
      updateIcons(document.documentElement.getAttribute("data-theme"));
    });
  </script>
</body>

</html>
